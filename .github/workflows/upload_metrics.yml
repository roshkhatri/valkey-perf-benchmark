name: Upload multiple benchmark results to S3

on:
  workflow_call:
    inputs:
      commit_ids:
        required: true
        type: string     # JSON array
      results_dir_root:
        required: true
        type: string     # e.g., ${{ github.workspace }}/results

jobs:
  upload:
    runs-on: ubuntu-latest

    steps:
      - name: Install tooling
        run: sudo apt-get update && sudo apt-get install -y jq awscli

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ secrets.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}

      - name: Upload all results to S3
        env:
          COMMITS_JSON: ${{ inputs.commit_ids }}
          ROOT_DIR: ${{ inputs.results_dir_root }}
        run: |
          commits=$(echo "$COMMITS_JSON" | jq -r '.[]')
          for sha in $commits; do
            echo "Uploading metrics for $sha"
            aws s3 cp "$ROOT_DIR/$sha/metrics.json" \
              "s3://valkey-benchmark-results/results/$sha/metrics.json"
            aws s3 cp "$ROOT_DIR/$sha/logs.txt" \
              "s3://valkey-benchmark-results/results/$sha/logs.txt"
          done

      - name: Update completed_commits.json
        run: |
          tmp=$(mktemp)
          aws s3 cp s3://valkey-benchmark-results/completed_commits.json "$tmp" \
            || echo '[]' > "$tmp"

          updated=$(jq -s 'add | unique' "$tmp" <(echo "$COMMITS_JSON"))
          echo "$updated" > new_completed.json
          aws s3 cp new_completed.json s3://valkey-benchmark-results/completed_commits.json
