name: Upload multiple benchmark results to S3

on:
  workflow_call:
    inputs:
      commit_ids:
        required: true
        type: string     # JSON array
      results_dir_root:
        required: true
        type: string     # e.g., ${{ github.workspace }}/results

jobs:
  upload:
    runs-on: ubuntu-latest

    steps:
      - name: Install tooling
        run: sudo apt-get update && sudo apt-get install -y jq awscli

      - name: Upload all results to S3
        env:
          AWS_REGION: us-east-1
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          COMMITS_JSON: ${{ inputs.commit_ids }}
          ROOT_DIR: ${{ inputs.results_dir_root }}
        run: |
          commits=$(echo "$COMMITS_JSON" | jq -r '.[]')
          for sha in $commits; do
            echo "Uploading metrics for $sha"
            aws s3 cp "$ROOT_DIR/$sha/metrics.json" \
              "s3://valkey-benchmark-results/results/$sha/metrics.json"
            aws s3 cp "$ROOT_DIR/$sha/logs.txt" \
              "s3://valkey-benchmark-results/results/$sha/logs.txt"
          done

      - name: Update completed_commits.json
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          COMMITS_JSON: ${{ inputs.commit_ids }}
        run: |
          tmp=$(mktemp)
          aws s3 cp s3://valkey-benchmark-results/completed_commits.json "$tmp" \
            || echo '[]' > "$tmp"

          updated=$(jq -s 'add | unique' "$tmp" <(echo "$COMMITS_JSON"))
          echo "$updated" > new_completed.json
          aws s3 cp new_completed.json s3://valkey-benchmark-results/completed_commits.json
